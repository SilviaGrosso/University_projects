{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to work on the files:\n",
    "*  [Books](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Books.csv.gz)\n",
    "*  [Book ratings](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Book-Ratings.csv.gz)\n",
    "*  [Users](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Users.csv.gz)\n",
    "*  [Goodbooks books](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks.csv.gz)\n",
    "*  [Goodbooks ratings](https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks-ratings.csv.gz)\n",
    "\n",
    "### Notes\n",
    "\n",
    "1.    It is mandatory to use GitHub for developing the project.\n",
    "1.    The project must be a jupyter notebook.\n",
    "1.    There is no restriction on the libraries that can be used, nor on the Python version.\n",
    "1.    To read those files, you need to use the `encoding = 'latin-1'` option.\n",
    "1.    All questions on the project **must** be asked in a public channel on [Zulip](https://focs.zulipchat.com), otherwise no  answer will be given."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Progetto di _Foundations of Computer Science_\n",
    "\n",
    "Camagni Valentina (878252), Grosso Silvia (881993), Merelli Elisa (881427)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LIBRERIE:\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importo i dati:\n",
    "usiamo l'encoding richiesto 'latin-1', e la modalità di compression = 'gzip'; inoltre impostiamo il parametro low_memory = False, come segnalato da un Warning. I primi tre file sono sono separati da ';', mentre gli ultimi due da ',', infine usiamo *dtype* per verificare il tipo del contentuo dei campi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Books.csv.gz\", compression = 'gzip', sep =';', escapechar = '\\\\', encoding = 'latin-1', low_memory=False, dtype = {'Year-Of-Publication':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ISBN                                                          078946697X\n",
       "Book-Title             DK Readers: Creating the X-Men, How It All Beg...\n",
       "Book-Author                                           Michael Teitelbaum\n",
       "Year-Of-Publication                                                 2000\n",
       "Publisher                                              DK Publishing Inc\n",
       "Image-URL-S            http://images.amazon.com/images/P/078946697X.0...\n",
       "Image-URL-M            http://images.amazon.com/images/P/078946697X.0...\n",
       "Image-URL-L            http://images.amazon.com/images/P/078946697X.0...\n",
       "Name: 209538, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#aggiungendo l'escape character '\\\\' in books non ho errore in questo record\n",
    "books.iloc[209538]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Book-Ratings.csv.gz\", compression = 'gzip', sep =';', encoding = 'latin-1', dtype = {'User-ID':'int64',\n",
    "                              'Book-Rating':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/Users.csv.gz\", compression = 'gzip', sep =';', encoding = 'latin-1', dtype = {'User-ID': 'int64',\n",
    "                            'Age':'float64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks.csv.gz\", compression = 'gzip', sep =',', encoding = 'latin-1', \n",
    "                       dtype = {range(1,5) :'int64', \n",
    "                              'original_publication_year':'float64',\n",
    "                              'average_rating':'float64',\n",
    "                              'ratings_count':'int64', \n",
    "                              'work_ratings_count':'int64', \n",
    "                              'work_text_reviews_count':'int64',\n",
    "                              'ratings_1':'int64',\n",
    "                              'ratings_2':'int64', \n",
    "                              'ratings_3':'int64',\n",
    "                              'ratings_4':'int64', \n",
    "                              'ratings_5':'int64'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rat = pd.read_csv(\"https://github.com/gdv/foundationsCS/raw/master/progetti/2021/goodbooks-ratings.csv.gz\", compression = 'gzip', sep =',', encoding = 'latin-1', dtype = {range(1,3):'int64'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esploriamo i dati appena caricati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bookrat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_rat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_rat.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Normalize the location field of *Users* dataset, splitting into city, region, country."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo osservato che in *'Location'* le stringhe sono separate da virgola e spazio. Utilizzo il metodo split specificando l'espressione regolare di separazione in pat:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split=users['Location'].str.split(',\\s', expand=True)\n",
    "split[split[8].isna()==False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che di default vengono creati 9 colonne poichè, evidentemente, vi sono degli users con più campi relativamente alla *'Location'*. Decidiamo di definire attraverso una regex il formato *'Location'* che desideriamo. Gli users che non soddisfano tale pattern non verranno considerati:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users=users[users['Location'].str.match(\"^([a-zA-Z\\.\\s\\/-]+|\"\"),([a-zA-Z\\.\\s\\/-]+|\"\"),([a-zA-Z\\.\\s\\/-]+|\"\")$\")==True].reset_index(drop=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splittiamo la colonna Location nei 3 campi *'City'*, *'Region'*, *'Country'*, richiesti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users[['City','Region','Country']]=users['Location'].str.split(',\\s', expand=True)\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopodiché definiamo un nuovo dataframe *users_normalize* dove rimuoviamo la colonna *'Location'*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_normalize = users.drop('Location', 1)\n",
    "users_normalize.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. For each book in the *Books* dataset, compute its average rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Osservando i dataset, si vede che il dataset *book_rat* vi son più righe riferite allo stesso ISBN in quanto riportano valutazioni di Users differenti. Dunque raggruppiamo per ISBN e calcoliamo la media del 'rating'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat.groupby('ISBN').mean()['Book-Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifichiamo sul secondo ISBN: qui la media dovrebbe essere 18/7=2.57, e non torna con il valore indicato in Book-Rating. Individuiamo le righe conteneti la stringa '0375404120' in ISBN con il metodo *contains*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat[bookrat['ISBN']=='0375404120']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat[bookrat['ISBN'].str.contains('0375404120')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notiamo che vi sono più righe che contengono la stringa '0375404120' rispetto alla ricerca precendente dunque deduciamo che la presenza di spazi all'inizio e alla fine della stringa hanno introdotto errori nel raggruppamento:\n",
    "infatti verifichiamo che inserendo uno spazio all'inizio della stringa torna il risultato mostrato nella colonna Book-Rating iniziale:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat[bookrat['ISBN'].str.contains(' 0375404120')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quindi decidiamo di togliere tutti gli spazi a capo e coda delle stringhe dalla colonna ISBN attraverso il metodo strip, nei dataframe *books* e *bookrat*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bookrat.ISBN = bookrat.ISBN.str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.ISBN = books.ISBN.str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ora possiamo applicare il group by per dividere in base all'ISBN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifichiamo as_index = False per non avere ISBN come indice\n",
    "\n",
    "bookrat_avg = bookrat.groupby('ISBN', as_index = False).mean()[['ISBN','Book-Rating']]\n",
    "bookrat_avg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora possiamo fare il merge dei due dataframe sull'ISBN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_bookrat_avg = pd.merge(books, bookrat_avg, how = 'left', on = 'ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_bookrat_avg['Book-Rating']=books_bookrat_avg['Book-Rating'].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_bookrat_avg[['ISBN','Book-Title','Book-Author','Book-Rating']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. For each book in the *GoodBooks* dataset, compute its average rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si osserva che è presente la colonna contenente le valutazioni medie per ogni libro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_books[['book_id','isbn','original_title','average_rating']].set_index('book_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Controlliamo che i valori contenuti nella colonna *'average_rating'* corrispondano alla media pesata del numero di persone che hanno votato da 1 a 5 (contenuto nelle colonne *'ratings_1-5'*) sul numero totale di persone che hanno votato (contenuto in *'work_ratings_count'*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifichiamo sia vero (quante uguaglianze false) che per ogni riga che la somma dei 5 valori di ratings_1-5 dia 'work_ratings_count':\n",
    "gb_books[(gb_books['work_ratings_count'] == gb_books['ratings_1'] + gb_books['ratings_2'] + gb_books['ratings_3'] + gb_books['ratings_4'] + gb_books['ratings_5']) == False].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verifichiamo ora la corrispondenza dei valori delle medie:\n",
    "gb_books[(gb_books['average_rating'] == ((gb_books['ratings_1']*1 + gb_books['ratings_2']*2 + gb_books['ratings_3']*3 + gb_books['ratings_4']*4 + gb_books['ratings_5']*5)/(gb_books['work_ratings_count'])).round(2)) == False].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Merge together all rows sharing the same book title, author and publisher. We will call the resulting datset `merged books`. The books that have not been merged together will not appear in `merged books`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Come prima cosa creiamo *merge* in cui raggruppiamo con i tre attributi *'Book-Title'*, *'Book-Author'* e *'Publisher'*, riportando il conteggio delle ricorrenze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as_index = False per fare si che le colonne 'Book-Title', 'Book-Author', 'Publisher' rimangano tali e non diventino indice:\n",
    "merge = books.groupby(['Book-Title', 'Book-Author', 'Publisher'], as_index = False).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora consideraimo solo i dati che appaiono più di una volta (come having di SQL):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books = merge[merge['ISBN']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books = merged_books[['Book-Title', 'Book-Author', 'Publisher','ISBN']].rename({'ISBN':'count'}, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_books)\n",
    "# I libri con stesso titolo, autore e editore sono 4725."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. For each book in `merged books` compute its average rating.\n",
    "\n",
    "The average is computed considering all books in `books` that have been merged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unisco le tabelle *books* e *bookrat* con ISBN chiave primaria di *books* (già \"puliti\" precedentemente), in modo da avere per ogni libro in *book* la votazione data da ogni User che lo ha valutato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books_bookrat = pd.merge(books, bookrat, how = 'left',on = 'ISBN')\n",
    "books_bookrat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Facciamo una left join tra *merged_books* e *books_bookrat*, con *'Book-Title'*, *'Book-Author'* e *'Publisher'*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books_bookrat = pd.merge(merged_books[['Book-Title', 'Book-Author', 'Publisher']],books_bookrat , how = 'left', on = ['Book-Title', 'Book-Author', 'Publisher'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books_bookrat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(merged_books_bookrat)\n",
    "# Otteniamo un numero di records maggiore: infatti, lo stesso libro individuato da 'Book-Title', 'Book-Author' e \n",
    "# 'Publisher' può avere edizioni e quindi ISBN differenti, e per ogni edizione, valutazioni da utenti differenti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per ogni libro in *merged_books*, calcoliamo la media delle valutazioni degli utenti, raggruppando anche per *'ISBN'*, ottenendo così la media per ogni edizione:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_books_avg = merged_books_bookrat.groupby(['Book-Title', 'Book-Author', 'Publisher', 'ISBN'], as_index = False).mean('Book-Rating').round(2)[['Book-Title', 'Book-Author', 'Publisher','Book-Rating','ISBN']].rename({'Book-Rating':'Avg-Rating'}, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abbiamo ottenuto un numero maggiore del numero di libri in *merged_books*, questo perchè in questa tabella possiamo sapere, per ogni libro che ha avuto più edizioni, la valutazione media di ogni singola edizione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "merged_books_avg.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. For each book in `merged books` compute the minimum and maximum of the average ratings over all corresponding books in the `books` dataset.\n",
    "\n",
    "Hence for each book in `merged books` we will have exactly two values (a minimum and a maximum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*merged_books_avg* è il dataframe che contiene per ogni libro di *merged_books* (definito da Title, Author, Publisher) la media dei ratings su ogni edizione (ISBN). E', quindi, sufficiente calcolare il minimo e il massimo avg_rating raggruppando per i tre attributi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmin = merged_books_avg.groupby(['Book-Title','Book-Author','Publisher'], as_index = False).min()[['Book-Title','Book-Author','Publisher','Avg-Rating']].rename({'Avg-Rating':'Min-Rating'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seriemax = merged_books_avg.groupby(['Book-Title','Book-Author','Publisher'], as_index = False).max()['Avg-Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([dfmin,seriemax], axis = 1).reset_index(drop= True).rename({'Avg-Rating':'Max-Rating'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Osserviamo che come ci si aspetterebbe, otteniamo nuovamente 4725 righe come in merged_books."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. For each book in `goodbooks`, compute the list of its authors. Assuming that the number of reviews with a text (column `work_text_reviews_count`) is split equally among all authors, find for each authors the total number of reviews with a text. We will call this quantity the *shared number of reviews with a text*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_books.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo una lista con gli autori:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_autori = gb_books.authors.str.split(', ').tolist() \n",
    "lista_autori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un dizionario *libri_autori* che abbia come chiavi i valori contenuti nella colonna *'book_id'* di *gb_books*, e come valore una lista contenete gli autori del libro:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "libri_autori={}\n",
    "for i in list(gb_books['book_id']):\n",
    "    libri_autori[i] = lista_autori[i-1]\n",
    "                                        # il -1 gestisce il fatto che l'indice implicito di gb_books parta\n",
    "                                        # da zero, mentre book_id parta da uno.\n",
    "libri_autori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seconda parte dell'esercizio richiede di calcolare per ogni autore lo *shared number of reviews with a text*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creo una lista degli autori come somma delle liste presenti in lista_autori, senza duplicati(set) e ordinati (sorted):\n",
    "singoli_autori = sorted(set(sum(lista_autori,[])))\n",
    "singoli_autori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo la serie *rev* come copia di *'work_text_reviews_count'* e poi ad ogni elemento sostituisco la porzione di *shared number of reviews with a text* che andrà assegnata a ciascun coautore del libro, ossia divido il valore di *'work_text_reviews_count'* per il numero di autori che hanno scritto il libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = gb_books['work_text_reviews_count'].copy()\n",
    "for i in range(len(rev)):\n",
    "    rev[i] = rev[i]/len(libri_autori[i+1])\n",
    "rev  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un dizionario che associa a ciascun autore lo *'shared number of reviews with a text'*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shar_num_rev = {}\n",
    "for autore in singoli_autori:\n",
    "    shar_num_rev[autore]=0\n",
    "    for i in libri_autori:\n",
    "        if autore in libri_autori[i]:\n",
    "            shar_num_rev[autore]+=rev[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shar_num_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. For each year of publication, determine the author that has the largest value of the shared number of reviews with a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creiamo un insieme di anni in cui sono stati pubblicati libri:\n",
    "years = set(gb_books['original_publication_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un dizionario che ha come chiavi gli anni di pubblicazione (*'original_publication_year'*) e come valori la lista degli autori dei libri che hanno pubblicato in quell'anno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_authors = {}\n",
    "for year in list(years):\n",
    "    year_authors[year] = []\n",
    "    for i in gb_books.book_id:\n",
    "        if gb_books.original_publication_year[i-1] == year:\n",
    "            year_authors[year]+=gb_books.authors[i-1].split(', ')\n",
    "year_authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un nuovo dizionario in cui le chiavi sono gli anni di pubblicazione e i valori sono gli autori che hanno pubblicato in quell'anno con maggiore numero di *shared number of reviews with a text*; in caso di parità vengono stampati tutti gli autori con tale valore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_max_rev={}\n",
    "for year in years:\n",
    "    massimo=0\n",
    "    anno_max_rev[year]=[]\n",
    "    for autore in year_authors[year]:\n",
    "        if shar_num_rev[autore]>=massimo:\n",
    "            massimo=shar_num_rev[autore]\n",
    "            anno_max_rev[year]+=[autore]\n",
    "            \n",
    "anno_max_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Assuming that there are no errors in the ISBN fields, find the books in both datasets, and compute the difference of average rating according to the ratings and the goodratings datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definiamo *diff_avg* il merge tra i dataset *books_bookrat_avg* (contenente per ogni libro in *books* il rating medio) e *gb_books* (dove per ogni libro vi è già l'average rating in *'Average-Rating'*).\n",
    "La differenza dell'average rating è calcolata dalla semplice differenza delle due colonne per ogni libro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_avg = pd.merge(books_bookrat_avg,gb_books, how = 'inner', left_on='ISBN', right_on='isbn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_avg['diff_avg'] = diff_avg['Book-Rating']-diff_avg['average_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_avg[['ISBN','Book-Title','Year-Of-Publication','Publisher','Book-Rating','average_rating','diff_avg']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Split the users dataset according to the age. One dataset contains the users with unknown age, one with age 0-14, one with age 15-24, one with age 25-34, and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo innanzitutto il DataFrame contenente gli users con età sconosciuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown = users[users['Age'].isna()].reset_index(drop=True)\n",
    "df_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo la lista con i ranges d'età:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges= [-1]+[i for i in range(14,int(users.Age.max())+1,10)]\n",
    "ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo il dizionario le cui chiavi sono i nomi dei DataFrame distinti per età, e i valori sono i DataFrame contenenti l'insieme dei record degli users filtrati per età associata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta = {}\n",
    "for i in range(0,len(ranges)-1):\n",
    "    classi_eta[\"df_{0}\".format(ranges[i+1])] = users[(users['Age']>ranges[i])&(users['Age']<=ranges[i+1])].sort_values('Age').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta['df_14']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi_eta['df_244']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Find the books that appear only in the goodbooks datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stampiamo i libri con ISBN in *good_books* che non sia in *books* (eseguiamo l'equivalente pandas del comando NOT IN di SQL)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gb_books[~ gb_books['isbn'].isin(books['ISBN'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. Assuming that each pair (author, title) identifies a book, for each book find the number of times it appears in the books dataset. Which books appear the most times?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raggruppiamo in *times* i record di *books* secondo la coppia (*'Book-Title'*, *'Book-Author'*) e contiamo la numerosità di ogni gruppo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times = books.groupby(['Book-Title','Book-Author'], as_index = False).count()[['Book-Title','Book-Author','ISBN']].rename({'ISBN':'count'}, axis = 1)\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostriamo la coppia (*'Book-Title'*, *'Book-Author'*) con il conteggio massimo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times[times['count'] == times['count'].max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. Find the author with the highest average rating according to the goodbooks datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creaimo un dizionario che associa ad ogni autore tutti i *book_id* in cui è presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "autori_libri = {}\n",
    "for autore in singoli_autori:\n",
    "    autori_libri[autore]=[]\n",
    "    for book_id in libri_autori:\n",
    "        if autore in libri_autori[book_id]:  \n",
    "            autori_libri[autore]+=[book_id]\n",
    "autori_libri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creiamo un dizionario che ad ogni autore associa il valore di *average_rating* dei libri in cui è presente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "high_avg_au = {}\n",
    "for autore in singoli_autori:\n",
    "    high_avg_au[autore]=[]\n",
    "    for i in autori_libri[autore]:\n",
    "        high_avg_au[autore]+=[gb_books.average_rating[i-1]]\n",
    "    \n",
    "high_avg_au"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associamo ad ogni autore il valore medio degli *average_rating* associati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_rating = {}\n",
    "for autore in high_avg_au:\n",
    "    avg_rating[autore] = np.mean(high_avg_au[autore]).round(2)\n",
    "avg_rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Individuiamo l'autore con massimo valore medio di *average_rating*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(avg_rating, key = avg_rating.get), max(avg_rating.values())   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
